{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Real-Time Face Recognition using OpenCV\n","\n","### Objective:\n","To understand how to implement simple real-time face recognition using the Haar Cascade classifier and LBPH (Local Binary Patterns Histograms) face recognizer in OpenCV. This exercise will guide students through the process of preparing training data, training the recognizer, and performing real-time face recognition with a webcam.\n","\n","### Prerequisites:\n","- Installed OpenCV library (opencv-contrib-python)."]},{"cell_type":"markdown","metadata":{},"source":["## Step 1: Import the Necessary Libraries\n","\n","First, we need to import the OpenCV library and other necessary libraries."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2: Load the Haar Cascade Classifier\n","\n","The Haar Cascade classifier is a pre-trained model for face detection provided by OpenCV. We load the classifier from the pre-defined XML file."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Load the Haar Cascade XML file\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3: Prepare the Training Data\n","\n","We prepare the training data by loading images from `known_faces` directory, converting them to grayscale, detecting faces, and extracting the face regions. Each image file is named after the person in the image."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Path to the directory containing images of known faces\n","known_faces_dir = 'known_faces'\n","\n","def prepare_training_data(data_folder_path):\n","    faces = []\n","    labels = []\n","    subjects = []\n","\n","    # Iterate through each image file in the directory\n","    for filename in os.listdir(data_folder_path):\n","        if filename.endswith('.jpg') or filename.endswith('.png'):\n","            # Load the image\n","            image_path = os.path.join(data_folder_path, filename)\n","            image = cv2.imread(image_path)\n","            \n","            # Convert the image to grayscale\n","            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","            \n","            # Detect face in the image\n","            face = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","            \n","            if len(face) != 0:\n","                (x, y, w, h) = face[0]\n","\n","                # Apply offset to crop the face with a margin\n","                offset = 10  # You can adjust this value as needed\n","                x = max(x - offset, 0)\n","                y = max(y - offset, 0)\n","                w = min(w + 2 * offset, gray.shape[1] - x)\n","                h = min(h + 2 * offset, gray.shape[0] - y)\n","\n","                face_region = gray[y:y+h, x:x+w]\n","                faces.append(face_region)\n","                labels.append(len(subjects))  # Label as the index of the person in the subjects list\n","                subjects.append(os.path.splitext(filename)[0])  # Add the name (filename without extension)\n","\n","    return faces, labels, subjects\n","\n","# Prepare training data\n","faces, labels, subjects = prepare_training_data(known_faces_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4: Train the LBPH Face Recognizer\n","\n","We create and train the LBPH face recognizer using the prepared faces and labels."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Create and train the LBPH face recognizer\n","face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n","face_recognizer.train(faces, np.array(labels))"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5: Initialize the Webcam\n","\n","We open a connection to the webcam using OpenCV's `VideoCapture` method. The parameter `0` indicates that we want to use the default webcam."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Open a connection to the webcam\n","cap = cv2.VideoCapture(0)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 6: Capture Frames in a Loop\n","\n","- We continuously capture frames from the webcam in a loop until the user decides to exit.\n","- Face detection works better on grayscale images, so we convert the captured frame from BGR to grayscale.\n","- Using the Haar Cascade classifier, we detect faces in the grayscale frame. The `detectMultiScale` method returns the coordinates and dimensions of the bounding boxes around detected faces.\n","- For each detected face, we predict the label and confidence using the LBPH face recognizer. We then draw a custom bounding box and display the name of the recognized face.\n","- We display the frame with the recognized faces and the custom bounding boxes in a window named 'Face Detection'.\n","- We break the loop and stop the webcam feed when the user presses the `q` key on the keyboard.\n","- After breaking the loop, we release the webcam and close all OpenCV windows."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["-1"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["while True:\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","    \n","    if not ret:\n","        break\n","\n","    # Convert the frame to grayscale (Haar Cascade works with grayscale images)\n","    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Detect faces using Haar Cascade\n","    faces_detected = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","\n","    for (x, y, w, h) in faces_detected:\n","        # Extract the region of interest (ROI) of the face in the grayscale frame\n","        roi_gray = gray_frame[y:y+h, x:x+w]\n","        \n","        # Predict the label (person) and confidence (how sure the recognizer is) for the detected face\n","        label, confidence = face_recognizer.predict(roi_gray)\n","        \n","        # Determine the name of the recognized person based on the label\n","        if confidence < 80:\n","            label_text = subjects[label]\n","            color = (0, 255, 0)  # Green color for known faces\n","        else:\n","            label_text = \"Unknown\"\n","            color = (0, 0, 255)  # Red color for unknown faces\n","        \n","        # Draw capture icon style bounding box around detected faces\n","        line_length = 30  # Length of the corner lines\n","        thickness = 2  # Thickness of the lines\n","        \n","        # Top-left corner\n","        cv2.line(frame, (x, y), (x + line_length, y), color, thickness)\n","        cv2.line(frame, (x, y), (x, y + line_length), color, thickness)\n","        \n","        # Top-right corner\n","        cv2.line(frame, (x + w, y), (x + w - line_length, y), color, thickness)\n","        cv2.line(frame, (x + w, y), (x + w, y + line_length), color, thickness)\n","        \n","        # Bottom-left corner\n","        cv2.line(frame, (x, y + h), (x + line_length, y + h), color, thickness)\n","        cv2.line(frame, (x, y + h), (x, y + h - line_length), color, thickness)\n","        \n","        # Bottom-right corner\n","        cv2.line(frame, (x + w, y + h), (x + w - line_length, y + h), color, thickness)\n","        cv2.line(frame, (x + w, y + h), (x + w, y + h - line_length), color, thickness)\n","        \n","        # Display the name of the detected face\n","        cv2.putText(frame, label_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, thickness)\n","\n","        # Display the confidence value below the name\n","        cv2.putText(frame, f'Confidence: {confidence:.2f}', (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Face Detection', frame)\n","\n","    # Break the loop on 'q' key press\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        cap.release()\n","        break\n","\n","# When everything done, release the capture\n","cv2.destroyAllWindows()\n","cv2.waitKey(1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
