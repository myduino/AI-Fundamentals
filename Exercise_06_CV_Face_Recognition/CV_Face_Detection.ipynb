{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Face Detection using OpenCV\n",
    "\n",
    "### Objective:\n",
    "To understand how to implement simple real-time face detection using the Haar Cascade classifier in OpenCV and visualize the detected faces with a custom bounding box style.\n",
    "\n",
    "### Prerequisites:\n",
    "- Installed OpenCV library (opencv-contrib-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the Necessary Libraries\n",
    "\n",
    "First, we need to import the OpenCV library which provides the necessary tools for face detection and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Haar Cascade Classifier\n",
    "\n",
    "The Haar Cascade classifier is a pre-trained model for face detection provided by OpenCV. We load the classifier from the pre-defined XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar Cascade XML file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Webcam\n",
    "\n",
    "We open a connection to the webcam using OpenCV's `VideoCapture` method. The parameter `0` indicates that we want to use the default webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Capture Frames in a Loop\n",
    "\n",
    "- We continuously capture frames from the webcam in a loop until the user decides to exit.\n",
    "- Face detection works better on grayscale images, so we convert the captured frame from BGR to grayscale.\n",
    "- Using the Haar Cascade classifier, we detect faces in the grayscale frame. The `detectMultiScale` method returns the coordinates and dimensions of the bounding boxes around detected faces.\n",
    "- For each detected face, we draw a custom bounding box with corner lines to highlight the detected face. We also optionally display a label indicating a face has been detected.\n",
    "- We display the frame with the detected faces and the custom bounding boxes in a window named `Face Detection`.\n",
    "- We break the loop and stop the webcam feed when the user presses the `q` key on the keyboard.\n",
    "- After breaking the loop, we release the webcam and close all OpenCV windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale (Haar Cascade works with grayscale images)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw bounding box around detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw corner lines for capture icon style\n",
    "        line_length = 30  # Length of the corner lines\n",
    "        color = (255, 0, 0)  # Color of the bounding box (Blue in BGR)\n",
    "        thickness = 2  # Thickness of the lines\n",
    "        \n",
    "        # Top-left corner\n",
    "        cv2.line(frame, (x, y), (x + line_length, y), color, thickness)\n",
    "        cv2.line(frame, (x, y), (x, y + line_length), color, thickness)\n",
    "        \n",
    "        # Top-right corner\n",
    "        cv2.line(frame, (x + w, y), (x + w - line_length, y), color, thickness)\n",
    "        cv2.line(frame, (x + w, y), (x + w, y + line_length), color, thickness)\n",
    "        \n",
    "        # Bottom-left corner\n",
    "        cv2.line(frame, (x, y + h), (x + line_length, y + h), color, thickness)\n",
    "        cv2.line(frame, (x, y + h), (x, y + h - line_length), color, thickness)\n",
    "        \n",
    "        # Bottom-right corner\n",
    "        cv2.line(frame, (x + w, y + h), (x + w - line_length, y + h), color, thickness)\n",
    "        cv2.line(frame, (x + w, y + h), (x + w, y + h - line_length), color, thickness)\n",
    "        \n",
    "        # Optionally, display the detected face label\n",
    "        cv2.putText(frame, 'Face Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, thickness)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
