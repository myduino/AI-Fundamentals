{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Car Acceptibility\n",
    "\n",
    "Let's walk through a machine learning workflow to classify the acceptability of a car (acceptable or unacceptable) based on the features provided. We'll start by adding the headers, then proceed step-by-step through the ML workflow.\n",
    "\n",
    "Source of dataset from [Kaggle](https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set)\n",
    "\n",
    "## Data Attributes\n",
    "1. `buying`: Car buying price (categorical: 'vhigh', 'high', 'med', 'low')\n",
    "2. `maint`: Maintenance price (categorical: 'vhigh', 'high', 'med', 'low')\n",
    "3. `door`: Number of doors (categorical: '2', '3', '4', '5more')\n",
    "4. `persons`: Person capacity (categorical: '2', '4', 'more')\n",
    "5. `lug_boot`: Luggage boot size (categorical: 'small', 'med', 'big')\n",
    "6. `safety`: Safety of the car (categorical: 'low', 'med', 'high')\n",
    "7. `class`: Acceptability of the car (categorical: 'unacc', 'acc', 'good', 'vgood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Add Headers to the Data\n",
    "First, we'll load the data from the CSV file and add the headers.\n",
    "\n",
    "Explanation:\n",
    "- We'll use pandas to load the data.\n",
    "- Add headers to the dataset: `buying`, `maint`, `door`, `persons`, `lug_boot`, `safety`, `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data without headers\n",
    "data = pd.read_csv('car-evaluation.csv', header=None)\n",
    "\n",
    "# Add headers to the dataset\n",
    "headers = ['buying', 'maint', 'door', 'persons', 'lug_boot', 'safety', 'class']\n",
    "data.columns = headers\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "\n",
    "We'll encode categorical variables, handle any missing values, and prepare the data for training.\n",
    "\n",
    "Explanation:\n",
    "- Convert categorical variables to numerical using one-hot encoding.\n",
    "- Check for missing values and handle them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "data_encoded = pd.get_dummies(data, columns=['buying', 'maint', 'door', 'persons', 'lug_boot', 'safety'])\n",
    "\n",
    "# Display the first few rows of the encoded dataset\n",
    "print(data_encoded.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data_encoded.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split the Data into Training and Testing Sets\n",
    "\n",
    "We need to divide the dataset into training and testing sets to evaluate the model's performance.\n",
    "\n",
    "Explanation:\n",
    "- We'll use the train_test_split function from scikit-learn to split the data.\n",
    "- A common split is 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = data_encoded.drop('class', axis=1)\n",
    "y = data_encoded['class']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train a Machine Learning Model\n",
    "\n",
    "We'll train a model using a classification algorithm. For simplicity, we'll start with a K-Nearest Neighbours Classifier.\n",
    "\n",
    "Explanation:\n",
    "- We'll use the `KNeighborsClassifier` class from scikit-learn.\n",
    "- Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Model\n",
    "\n",
    "We'll evaluate the model's performance using metrics such as `accuracy`, `precision`, `recall`, and `F1-score`.\n",
    "\n",
    "Explanation:\n",
    "- Predict the target values for the test set.\n",
    "- Calculate evaluation metrics to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict the target values for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics\n",
    "\n",
    "#### Accuracy:\n",
    "\n",
    "Accuracy=0.8757\n",
    "\n",
    "- Explanation: Accuracy measures the proportion of correct predictions (both true positives and true negatives) among the total number of cases examined. An accuracy of 0.8757 means that the model correctly classified about 87.57% of the car acceptability cases.\n",
    "- Interpretation: The model has a high accuracy, indicating that it performs well overall in classifying car acceptability.\n",
    "\n",
    "#### Precision:\n",
    "\n",
    "Precision=0.7524\n",
    "\n",
    "- Explanation: Precision is the ratio of true positive predictions to the total number of positive predictions (true positives + false positives). A precision of 0.7524 means that about 75.24% of the cars predicted as \"acceptable\" (acc) by the model are actually acceptable.\n",
    "- Interpretation: The precision is moderately high, which means that the model is relatively good at identifying acceptable cars without too many false positives.\n",
    "\n",
    "#### Recall:\n",
    "\n",
    "Recall=0.5763\n",
    "\n",
    "- Explanation: Recall (also known as sensitivity or true positive rate) is the ratio of true positive predictions to the total number of actual positives (true positives + false negatives). A recall of 0.5763 means that about 57.63% of all actual acceptable cars were correctly identified by the model.\n",
    "- Interpretation: The recall is lower compared to precision, indicating that the model misses a significant number of acceptable cars (higher false negatives).\n",
    "\n",
    "#### F1-score:\n",
    "\n",
    "F1-score=0.6156\n",
    "\n",
    "- Explanation: The F1-score is the harmonic mean of precision and recall. It provides a single metric that balances both precision and recall. An F1-score of 0.6156 indicates a balance between precision and recall, but the value suggests there is room for improvement.\n",
    "- Interpretation: The F1-score is moderate, indicating that while the model is reasonably good at distinguishing between acceptable and unacceptable cars, there is a trade-off between precision and recall.\n",
    "\n",
    "\n",
    "### Summary\n",
    "- `Accuracy` (87.57%): High overall performance in classification.\n",
    "- `Precision` (75.24%): The model is good at correctly predicting acceptable cars, but there are some false positives.\n",
    "- `Recall` (57.63%): The model misses a notable proportion of acceptable cars, leading to false negatives.\n",
    "- `F1-score` (61.56%): The model balances precision and recall but suggests that there is room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Predict Car Acceptability for a Different Car Features\n",
    "\n",
    "- `Collect New Car Data`: Ensure the new data includes values for the features buying, maint, door, persons, lug_boot, and safety.\n",
    "- `Preprocess the New Data`: Ensure the new data is in the same format as the training data (i.e., one-hot encoded).\n",
    "- `Make Predictions`: Use the trained model to predict the class for the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted acceptability for the new car: vgood\n"
     ]
    }
   ],
   "source": [
    "# Data attributes information\n",
    "# `buying`: Car buying price (categorical: 'vhigh', 'high', 'med', 'low')\n",
    "# `maint`: Maintenance price (categorical: 'vhigh', 'high', 'med', 'low')\n",
    "# `door`: Number of doors (categorical: '2', '3', '4', '5more')\n",
    "# `persons`: Person capacity (categorical: '2', '4', 'more')\n",
    "# `lug_boot`: Luggage boot size (categorical: 'small', 'med', 'big')\n",
    "# `safety`: Safety of the car (categorical: 'low', 'med', 'high')\n",
    "\n",
    "# New car data\n",
    "new_car = {\n",
    "    'buying': 'med',\n",
    "    'maint': 'med',\n",
    "    'door': '1',\n",
    "    'persons': 'more',\n",
    "    'lug_boot': 'big',\n",
    "    'safety': 'high'\n",
    "}\n",
    "\n",
    "# Convert the new car data to a DataFrame\n",
    "new_car_data = pd.DataFrame([new_car])\n",
    "\n",
    "# One-hot encode the new car data to match the training data format\n",
    "new_car_encoded = pd.get_dummies(new_car_data)\n",
    "new_car_encoded = new_car_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Make a prediction\n",
    "new_car_prediction = knn.predict(new_car_encoded)\n",
    "\n",
    "print(f'Predicted acceptability for the new car: {new_car_prediction[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
