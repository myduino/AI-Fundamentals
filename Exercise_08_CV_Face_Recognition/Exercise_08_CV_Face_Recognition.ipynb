{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Real-Time Face Recognition using Face Recognition Module\n","\n","### Objective:\n","To understand how to implement real-time face recognition using the `face_recognition` library in combination with OpenCV for detecting and recognizing faces.\n","\n","### Prerequisites:\n","- Installed OpenCV library (opencv-contrib-python)."]},{"cell_type":"markdown","metadata":{},"source":["## Step 1: Import the Necessary Libraries\n","First, we need to import the OpenCV and face_recognition libraries which provide the necessary tools for face detection and recognition."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import face_recognition"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2: Load Known Faces and Their Encodings\n","We prepare our dataset of known faces. For each known person, we load their image, find the face encodings, and store them along with the person's name."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Path to the directory containing images of known faces\n","known_faces_dir = 'known_faces'\n","\n","# Lists to hold encodings and names\n","known_face_encodings = []\n","known_face_names = []\n","\n","# Load each known face and its encoding\n","for filename in os.listdir(known_faces_dir):\n","    if filename.endswith('.jpg') or filename.endswith('.png'):\n","        # Load the image\n","        image_path = os.path.join(known_faces_dir, filename)\n","        image = face_recognition.load_image_file(image_path)\n","        \n","        # Get the face encoding\n","        face_encoding = face_recognition.face_encodings(image)[0]\n","        \n","        # Store the encoding and the name\n","        known_face_encodings.append(face_encoding)\n","        known_face_names.append(os.path.splitext(filename)[0])"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3: Initialize the Webcam\n","We open a connection to the webcam using OpenCV's VideoCapture method. The parameter 0 indicates that we want to use the default webcam."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Open a connection to the webcam\n","cap = cv2.VideoCapture(0)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4: Capture Frames in a Loop\n","\n","- We continuously capture frames from the webcam in a loop until the user decides to exit.\n","- The face_recognition library requires frames in RGB format, so we convert the captured frame from BGR to RGB.\n","- Using the face_recognition library, we detect faces and get their encodings in the captured frame.\n","- For each detected face, we compare its encoding with the known face encodings to find matches.\n","- For each detected face, we draw a custom bounding box with corner lines to highlight the detected face. We also display the name of the recognized person.\n","- We display the frame with the detected faces and the custom bounding boxes in a window named 'Face Detection'.\n","- We break the loop and stop the webcam feed when the user presses the `q` key on the keyboard."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["while True:\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","    \n","    if not ret:\n","        break\n","    \n","    # Convert the frame to RGB\n","    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    \n","    # Detect faces\n","    face_locations = face_recognition.face_locations(rgb_frame)\n","    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n","    \n","    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n","        # Compare face encodings\n","        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n","\n","        # Find the known face with the smallest distance to the new face\n","        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n","        best_match_index = np.argmin(face_distances)\n","        if matches[best_match_index]:\n","            label_text = known_face_names[best_match_index]\n","            color = (0, 255, 0)  # Green for recognized faces\n","        else:\n","            label_text = \"Unknown\"\n","            color = (0, 0, 255)  # Red for unknown faces\n","        \n","        # Draw capture icon style bounding box around detected faces\n","        line_length = 30  # Length of the corner lines\n","        thickness = 2  # Thickness of the lines\n","        \n","        # Top-left corner\n","        cv2.line(frame, (left, top), (left + line_length, top), color, thickness)\n","        cv2.line(frame, (left, top), (left, top + line_length), color, thickness)\n","        \n","        # Top-right corner\n","        cv2.line(frame, (right, top), (right - line_length, top), color, thickness)\n","        cv2.line(frame, (right, top), (right, top + line_length), color, thickness)\n","        \n","        # Bottom-left corner\n","        cv2.line(frame, (left, bottom), (left + line_length, bottom), color, thickness)\n","        cv2.line(frame, (left, bottom), (left, bottom - line_length), color, thickness)\n","        \n","        # Bottom-right corner\n","        cv2.line(frame, (right, bottom), (right - line_length, bottom), color, thickness)\n","        cv2.line(frame, (right, bottom), (right, bottom - line_length), color, thickness)\n","        \n","        # Display the name of the detected face\n","        cv2.putText(frame, label_text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, thickness)\n","\n","        # Display the confidence value below the name\n","        distance_text = f\"Match Distance: {face_distances[best_match_index]:.2f}\"\n","        cv2.putText(frame, distance_text, (left, bottom + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, thickness)\n","    \n","    # Display the resulting frame\n","    cv2.imshow('Face Recognition', frame)\n","    \n","    # Break the loop on 'q' key press\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        cap.release()\n","        break\n","\n","# When everything done, release the capture\n","cv2.destroyAllWindows()\n","cv2.waitKey(1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
